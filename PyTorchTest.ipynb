{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Basic Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sources are from PyTorch website: \n",
    "https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.9955, 0.6352],\n",
      "        [0.1317, 0.4534, 0.1702],\n",
      "        [0.4217, 0.9209, 0.7331],\n",
      "        [0.1997, 0.0544, 0.8152],\n",
      "        [0.6405, 0.3840, 0.6557]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a random initialized matrix\n",
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a 5x3 matrix, uninitialized:\n",
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a matrix filled zeros and of dtype long\n",
    "x = torch.zeros(5,3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# Construct a tensor directly from data\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor based on an existing tensor. These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.2475, -0.4011,  0.8408],\n",
      "        [ 0.1580, -0.2158, -1.6077],\n",
      "        [-0.7198, -0.4919, -2.0045],\n",
      "        [-1.5156,  0.6089, -0.3042],\n",
      "        [ 1.0105,  0.1944,  0.4554]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5,3, dtype=torch.double)   #new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float) # override dtype!\n",
    "print(x)                                   # result has the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Get its size\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: ```torch.Size``` is in fact a tuple, so it supports all tuple operations.\n",
    "\n",
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7544,  0.5273,  1.0990],\n",
      "        [ 0.6674,  0.1656, -1.5419],\n",
      "        [-0.2497, -0.2469, -1.7595],\n",
      "        [-1.1562,  0.7213,  0.0902],\n",
      "        [ 1.9246,  0.9064,  1.2582]])\n",
      "tensor([[ 0.7544,  0.5273,  1.0990],\n",
      "        [ 0.6674,  0.1656, -1.5419],\n",
      "        [-0.2497, -0.2469, -1.7595],\n",
      "        [-1.1562,  0.7213,  0.0902],\n",
      "        [ 1.9246,  0.9064,  1.2582]])\n",
      "tensor([[ 0.7544,  0.5273,  1.0990],\n",
      "        [ 0.6674,  0.1656, -1.5419],\n",
      "        [-0.2497, -0.2469, -1.7595],\n",
      "        [-1.1562,  0.7213,  0.0902],\n",
      "        [ 1.9246,  0.9064,  1.2582]])\n",
      "tensor([[ 0.7544,  0.5273,  1.0990],\n",
      "        [ 0.6674,  0.1656, -1.5419],\n",
      "        [-0.2497, -0.2469, -1.7595],\n",
      "        [-1.1562,  0.7213,  0.0902],\n",
      "        [ 1.9246,  0.9064,  1.2582]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "\n",
    "# add\n",
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "\n",
    "result = torch.empty(5,3)  # providing an output tensor as argument\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "y.add_(x)                  #  in-place\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Any operation that mutates a tensor in-place is post-fixed with an ```_```. For example: ```x.copy_(y)```, ```x.t_()```, will change x.\n",
    "\n",
    "You can use standard NumPy-like indexing with all bells and whistles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4011, -0.2158, -0.4919,  0.6089,  0.1944])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Resizing: If you want to resize/reshape tensor, you can use torch.view\n",
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.5039])\n",
      "-1.503895998\n"
     ]
    }
   ],
   "source": [
    "# If you have a one element tensor, \n",
    "# use .item() to get the value as a Python number\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Bridge ##\n",
    "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
    "\n",
    "The Torch Tensor and NumPy array will share their underlying memory locations, and **changing one will change the other**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original a:\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "original b:\n",
      "[1. 1. 1. 1. 1.]\n",
      "changed a and b:\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Converting a Torch Tensor to a NumPy Array\n",
    "a = torch.ones(5)\n",
    "print(\"original a:\")\n",
    "print(a)\n",
    "\n",
    "b = a.numpy()\n",
    "print(\"original b:\")\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(\"changed a and b:\")\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Converting NumPy Array to Torch Tensor\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n",
    "\n",
    "## CUDA TENSORS ##\n",
    "Tensors can be moved onto any device using the ```.to``` method.\n",
    "\n",
    "```\n",
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
    "\n",
    "```\n",
    "\n",
    "expected output:\n",
    "```\n",
    "tensor([2.9218], device='cuda:0')\n",
    "tensor([2.9218], dtype=torch.float64)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
